{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYA Stock Prediction - Stacking Ensemble\n",
      "================================================================================\n",
      "Loaded 13947 rows\n",
      "Created 27 features, 13926 samples\n",
      "Train: 8913 | Val: 2228 | Test: 2785\n",
      "\n",
      "Training base models...\n",
      "Done.\n",
      "\n",
      "Training stacking model...\n",
      "\n",
      "Meta-model weights (alpha=1.0):\n",
      "  Ridge: 0.0255\n",
      "  RF: -0.0263\n",
      "  GradientBoosting: 0.0465\n",
      "  KNN: 0.0211\n",
      "  Intercept: -0.0000\n",
      "Done.\n",
      "\n",
      "================================================================================\n",
      "RESULTS\n",
      "================================================================================\n",
      "\n",
      "Return Prediction:\n",
      "           Model     RMSE      MAE\n",
      "           Ridge 0.011706 0.007726\n",
      "              RF 0.011236 0.007278\n",
      "GradientBoosting 0.011179 0.007270\n",
      "             KNN 0.011282 0.007468\n",
      "        Stacking 0.011089 0.007161\n",
      "\n",
      "Price Prediction:\n",
      "           Model       RMSE       MAE\n",
      "           Ridge 120.946710 80.028875\n",
      "              RF 115.368326 74.978170\n",
      "GradientBoosting 114.368975 74.830601\n",
      "             KNN 115.910783 77.140403\n",
      "        Stacking 113.447323 73.704231\n",
      "================================================================================\n",
      "\n",
      "Model saved: nya_model.pkl (14.03 MB)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# PHẦN 1: CÁC THUẬT TOÁN BASE MODELS\n",
    "# ============================================================================\n",
    "\n",
    "# --- 1.1 RIDGE REGRESSION ---\n",
    "def add_bias(X):\n",
    "    return np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "class RidgeRegression:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        self.w = None\n",
    "        self.X_mean = None\n",
    "        self.X_std = None\n",
    "        self.y_mean = None\n",
    "        self.y_std = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_mean = np.mean(X, axis=0)\n",
    "        self.X_std = np.std(X, axis=0) + 1e-8\n",
    "        X_norm = (X - self.X_mean) / self.X_std\n",
    "        \n",
    "        self.y_mean = np.mean(y)\n",
    "        self.y_std = np.std(y) + 1e-8\n",
    "        y_norm = (y - self.y_mean) / self.y_std\n",
    "        \n",
    "        Xb = add_bias(X_norm)\n",
    "        n = Xb.shape[1]\n",
    "        I = np.eye(n)\n",
    "        I[0, 0] = 0\n",
    "        \n",
    "        A = Xb.T @ Xb + (self.alpha + 1e-4) * I\n",
    "        b = Xb.T @ y_norm\n",
    "        \n",
    "        try:\n",
    "            self.w = np.linalg.solve(A, b)\n",
    "            if np.any(np.isnan(self.w)) or np.any(np.isinf(self.w)):\n",
    "                raise np.linalg.LinAlgError(\"NaN in weights\")\n",
    "        except np.linalg.LinAlgError:\n",
    "            try:\n",
    "                self.w = np.linalg.lstsq(A, b, rcond=1e-10)[0]\n",
    "                if np.any(np.isnan(self.w)):\n",
    "                    self.w = np.zeros(n)\n",
    "                    self.w[0] = self.y_mean\n",
    "            except:\n",
    "                self.w = np.zeros(n)\n",
    "                self.w[0] = self.y_mean\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.w is None:\n",
    "            return np.zeros(len(X))\n",
    "        X_norm = (X - self.X_mean) / self.X_std\n",
    "        y_pred_norm = add_bias(X_norm) @ self.w\n",
    "        return y_pred_norm * self.y_std + self.y_mean\n",
    "\n",
    "\n",
    "# --- 1.2 RANDOM FOREST ---\n",
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "class DecisionTreeRegressor:\n",
    "    def __init__(self, min_samples_split=10, max_depth=6, n_features=None):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_features = n_features\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.n_features is None:\n",
    "            self.n_features = int(np.sqrt(X.shape[1]))\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples = X.shape[0]\n",
    "        if depth >= self.max_depth or n_samples < self.min_samples_split:\n",
    "            return Node(value=np.mean(y))\n",
    "        \n",
    "        feature_idxs = np.random.choice(X.shape[1], self.n_features, replace=False)\n",
    "        best_split = self._get_best_split(X, y, feature_idxs)\n",
    "        \n",
    "        if best_split['var_red'] <= 0:\n",
    "            return Node(value=np.mean(y))\n",
    "        \n",
    "        left_tree = self._grow_tree(best_split['X_left'], best_split['y_left'], depth + 1)\n",
    "        right_tree = self._grow_tree(best_split['X_right'], best_split['y_right'], depth + 1)\n",
    "        \n",
    "        return Node(best_split['feature_idx'], best_split['threshold'], left_tree, right_tree)\n",
    "\n",
    "    def _get_best_split(self, X, y, feature_indices):\n",
    "        best_split = {'var_red': -1}\n",
    "        for feat_idx in feature_indices:\n",
    "            thresholds = np.percentile(X[:, feat_idx], np.linspace(10, 90, 10))\n",
    "            for threshold in thresholds:\n",
    "                left_mask = X[:, feat_idx] <= threshold\n",
    "                right_mask = ~left_mask\n",
    "                if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:\n",
    "                    continue\n",
    "                y_left, y_right = y[left_mask], y[right_mask]\n",
    "                var_red = np.var(y) - (len(y_left)/len(y) * np.var(y_left) + len(y_right)/len(y) * np.var(y_right))\n",
    "                if var_red > best_split['var_red']:\n",
    "                    best_split = {\n",
    "                        'feature_idx': feat_idx,\n",
    "                        'threshold': threshold,\n",
    "                        'X_left': X[left_mask],\n",
    "                        'y_left': y_left,\n",
    "                        'X_right': X[right_mask],\n",
    "                        'y_right': y_right,\n",
    "                        'var_red': var_red\n",
    "                    }\n",
    "        return best_split\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse(x, self.root) for x in X])\n",
    "\n",
    "    def _traverse(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self._traverse(x, node.left)\n",
    "        return self._traverse(x, node.right)\n",
    "\n",
    "class RandomForestRegressor:\n",
    "    def __init__(self, n_trees=100, max_depth=6, min_samples_split=10):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.trees = []\n",
    "        self.X_mean = None\n",
    "        self.X_std = None\n",
    "        self.y_mean = None\n",
    "        self.y_std = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_mean = np.mean(X, axis=0)\n",
    "        self.X_std = np.std(X, axis=0) + 1e-8\n",
    "        X_norm = (X - self.X_mean) / self.X_std\n",
    "        \n",
    "        self.y_mean = np.mean(y)\n",
    "        self.y_std = np.std(y) + 1e-8\n",
    "        y_norm = (y - self.y_mean) / self.y_std\n",
    "        \n",
    "        self.trees = []\n",
    "        for i in range(self.n_trees):\n",
    "            idxs = np.random.choice(len(X_norm), len(X_norm), replace=True)\n",
    "            tree = DecisionTreeRegressor(self.min_samples_split, self.max_depth)\n",
    "            tree.fit(X_norm[idxs], y_norm[idxs])\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_norm = (X - self.X_mean) / self.X_std\n",
    "        predictions = np.array([tree.predict(X_norm) for tree in self.trees])\n",
    "        y_pred_norm = np.mean(predictions, axis=0)\n",
    "        return y_pred_norm * self.y_std + self.y_mean\n",
    "\n",
    "\n",
    "# --- 1.3 GRADIENT BOOSTING ---\n",
    "class GradientBoosting:\n",
    "    def __init__(self, learning_rate=0.1, n_trees=100, max_depth=3):\n",
    "        self.lr = learning_rate\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "        self.X_mean = None\n",
    "        self.X_std = None\n",
    "        self.y_mean = None\n",
    "        self.y_std = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X_mean = np.mean(X, axis=0)\n",
    "        self.X_std = np.std(X, axis=0) + 1e-8\n",
    "        X_norm = (X - self.X_mean) / self.X_std\n",
    "        \n",
    "        self.y_mean = np.mean(y)\n",
    "        self.y_std = np.std(y) + 1e-8\n",
    "        y_norm = (y - self.y_mean) / self.y_std\n",
    "        \n",
    "        y_pred = np.zeros_like(y_norm)\n",
    "        \n",
    "        for tree_idx in range(self.n_trees):\n",
    "            residuals = y_norm - y_pred\n",
    "            tree = self._build_tree(X_norm, residuals, depth=0)\n",
    "            self.trees.append(tree)\n",
    "            tree_preds = self._predict_tree(tree, X_norm)\n",
    "            y_pred += self.lr * tree_preds\n",
    "    \n",
    "    def _build_tree(self, X, residuals, depth=0):\n",
    "        n_samples = X.shape[0]\n",
    "        if depth >= self.max_depth or n_samples < 10:\n",
    "            return {'type': 'leaf', 'value': np.mean(residuals)}\n",
    "        \n",
    "        best_gain = -np.inf\n",
    "        best_split = None\n",
    "        parent_var = np.var(residuals)\n",
    "        \n",
    "        for feat_idx in range(X.shape[1]):\n",
    "            thresholds = np.percentile(X[:, feat_idx], [25, 50, 75])\n",
    "            for threshold in thresholds:\n",
    "                left_mask = X[:, feat_idx] <= threshold\n",
    "                right_mask = ~left_mask\n",
    "                if np.sum(left_mask) < 5 or np.sum(right_mask) < 5:\n",
    "                    continue\n",
    "                left_var = np.var(residuals[left_mask])\n",
    "                right_var = np.var(residuals[right_mask])\n",
    "                gain = parent_var - (np.sum(left_mask) * left_var + np.sum(right_mask) * right_var) / n_samples\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_split = {\n",
    "                        'feat_idx': feat_idx,\n",
    "                        'threshold': threshold,\n",
    "                        'left_mask': left_mask,\n",
    "                        'right_mask': right_mask\n",
    "                    }\n",
    "        \n",
    "        if best_split is None or best_gain <= 0:\n",
    "            return {'type': 'leaf', 'value': np.mean(residuals)}\n",
    "        \n",
    "        left_tree = self._build_tree(X[best_split['left_mask']], residuals[best_split['left_mask']], depth + 1)\n",
    "        right_tree = self._build_tree(X[best_split['right_mask']], residuals[best_split['right_mask']], depth + 1)\n",
    "        \n",
    "        return {\n",
    "            'type': 'split',\n",
    "            'feat_idx': best_split['feat_idx'],\n",
    "            'threshold': best_split['threshold'],\n",
    "            'left': left_tree,\n",
    "            'right': right_tree\n",
    "        }\n",
    "    \n",
    "    def _predict_tree(self, tree, X):\n",
    "        predictions = np.zeros(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            node = tree\n",
    "            while node['type'] != 'leaf':\n",
    "                if X[i, node['feat_idx']] <= node['threshold']:\n",
    "                    node = node['left']\n",
    "                else:\n",
    "                    node = node['right']\n",
    "            predictions[i] = node['value']\n",
    "        return predictions\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_norm = (X - self.X_mean) / self.X_std\n",
    "        y_pred = np.zeros(X_norm.shape[0])\n",
    "        for tree in self.trees:\n",
    "            y_pred += self.lr * self._predict_tree(tree, X_norm)\n",
    "        return y_pred * self.y_std + self.y_mean\n",
    "\n",
    "\n",
    "# --- 1.4 KNN ---\n",
    "class KNNRegressor:\n",
    "    def __init__(self, n_neighbors=10):\n",
    "        self.k = n_neighbors\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_mean = None\n",
    "        self.X_std = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X_mean = np.mean(X, axis=0)\n",
    "        self.X_std = np.std(X, axis=0) + 1e-8\n",
    "        self.X_train = (X - self.X_mean) / self.X_std\n",
    "        self.y_train = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_norm = (X - self.X_mean) / self.X_std\n",
    "        predictions = []\n",
    "        for test_point in X_norm:\n",
    "            distances = np.sqrt(np.sum((self.X_train - test_point)**2, axis=1))\n",
    "            k_indices = np.argsort(distances)[:self.k]\n",
    "            weights = 1 / (distances[k_indices] + 1e-8)\n",
    "            predictions.append(np.sum(weights * self.y_train[k_indices]) / np.sum(weights))\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PHẦN 2: STACKING ENSEMBLE PREDICTOR\n",
    "# ============================================================================\n",
    "\n",
    "class NYAStackingPredictor:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.data = None\n",
    "        self.X_train = None\n",
    "        self.X_val = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_val = None\n",
    "        self.y_test = None\n",
    "        self.price_test = None\n",
    "        self.models = {}\n",
    "        self.meta_model = None\n",
    "        self.predictions = {}\n",
    "        \n",
    "    def load_and_filter_data(self):\n",
    "        df = pd.read_csv(self.file_path)\n",
    "        df = df[df['Index'] == 'NYA'].copy()\n",
    "        print(f\"Loaded {len(df)} rows\")\n",
    "        if 'Date' in df.columns:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df = df.sort_values('Date').reset_index(drop=True)\n",
    "        self.data = df\n",
    "        return self\n",
    "    \n",
    "    def create_features(self):\n",
    "        df = self.data.copy()\n",
    "        df['Price_Current'] = df['Adj Close']\n",
    "        df['Price_Next'] = df['Adj Close'].shift(-1)\n",
    "        df['Target_Return'] = (df['Price_Next'] - df['Price_Current']) / df['Price_Current']\n",
    "        \n",
    "        df['Return_1d'] = df['Adj Close'].pct_change()\n",
    "        df['Return_5d'] = df['Adj Close'].pct_change(5)\n",
    "        for i in [1, 2, 3, 5, 10]:\n",
    "            df[f'Return_Lag_{i}'] = df['Return_1d'].shift(i)\n",
    "        \n",
    "        close_prev = df['Adj Close'].shift(1)\n",
    "        df['MA_5'] = close_prev.rolling(window=5).mean()\n",
    "        df['MA_10'] = close_prev.rolling(window=10).mean()\n",
    "        df['MA_20'] = close_prev.rolling(window=20).mean()\n",
    "        df['Price_over_MA10'] = close_prev / (df['MA_10'] + 1e-8)\n",
    "        \n",
    "        df['Volatility_5'] = df['Return_1d'].rolling(window=5).std()\n",
    "        df['Volatility_10'] = df['Return_1d'].rolling(window=10).std()\n",
    "        df['Volatility_20'] = df['Return_1d'].rolling(window=20).std()\n",
    "        \n",
    "        df['Volume_MA_5'] = df['Volume'].shift(1).rolling(window=5).mean()\n",
    "        df['Volume_ratio'] = df['Volume'] / (df['Volume_MA_5'] + 1e-8)\n",
    "        \n",
    "        df['Momentum_5'] = df['Adj Close'] - df['Adj Close'].shift(5)\n",
    "        df['Momentum_10'] = df['Adj Close'] - df['Adj Close'].shift(10)\n",
    "        df['Momentum_pct_5'] = df['Momentum_5'] / (df['Adj Close'].shift(5) + 1e-8)\n",
    "        df['Momentum_pct_10'] = df['Momentum_10'] / (df['Adj Close'].shift(10) + 1e-8)\n",
    "        df['Price_Range'] = (df['High'] - df['Low']) / (df['Low'] + 1e-8)\n",
    "        \n",
    "        rolling_high_10 = df['High'].rolling(window=10).max()\n",
    "        rolling_low_10 = df['Low'].rolling(window=10).min()\n",
    "        df['HL_position_10'] = (df['Close'] - rolling_low_10) / (rolling_high_10 - rolling_low_10 + 1e-8)\n",
    "        \n",
    "        rolling_high_20 = df['High'].rolling(window=20).max()\n",
    "        rolling_low_20 = df['Low'].rolling(window=20).min()\n",
    "        df['HL_position_20'] = (df['Close'] - rolling_low_20) / (rolling_high_20 - rolling_low_20 + 1e-8)\n",
    "        \n",
    "        delta = df['Adj Close'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "        rs = gain / (loss + 1e-8)\n",
    "        df['RSI_14'] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        df = df.dropna()\n",
    "        \n",
    "        feature_cols = [c for c in df.columns if c.startswith(('Return', 'MA_', 'Price_', 'Vol', 'Momentum', 'HL', 'RSI'))]\n",
    "        print(f\"Created {len(feature_cols)} features, {len(df)} samples\")\n",
    "        \n",
    "        self.data = df\n",
    "        return self\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        exclude_cols = ['Date', 'Index', 'Close', 'Adj Close', 'Open', 'High', 'Low', \n",
    "                        'Volume', 'CloseUSD', 'Target_Return', 'Price_Current', 'Price_Next']\n",
    "        X = self.data.drop(columns=[col for col in exclude_cols if col in self.data.columns])\n",
    "        y = self.data['Target_Return']\n",
    "        price_current = self.data['Price_Current']\n",
    "        \n",
    "        n_total = len(X)\n",
    "        n_test = int(0.2 * n_total)\n",
    "        n_val = int(0.2 * (n_total - n_test))\n",
    "        \n",
    "        print(f\"Train: {n_total - n_test - n_val} | Val: {n_val} | Test: {n_test}\")\n",
    "        \n",
    "        self.X_train = X.iloc[:-(n_test + n_val)].values\n",
    "        self.y_train = y.iloc[:-(n_test + n_val)].values\n",
    "        \n",
    "        self.X_val = X.iloc[-(n_test + n_val):-n_test].values\n",
    "        self.y_val = y.iloc[-(n_test + n_val):-n_test].values\n",
    "        \n",
    "        self.X_test = X.iloc[-n_test:].values\n",
    "        self.y_test = y.iloc[-n_test:].values\n",
    "        self.price_test = price_current.iloc[-n_test:].values\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def train_base_models(self):\n",
    "        print(\"\\nTraining base models...\")\n",
    "        \n",
    "        self.models['Ridge'] = RidgeRegression(alpha=1.0)\n",
    "        self.models['Ridge'].fit(self.X_train, self.y_train)\n",
    "        \n",
    "        self.models['RF'] = RandomForestRegressor(n_trees=200, max_depth=8, min_samples_split=5)\n",
    "        self.models['RF'].fit(self.X_train, self.y_train)\n",
    "        \n",
    "        self.models['GradientBoosting'] = GradientBoosting(learning_rate=0.03, n_trees=300, max_depth=2)\n",
    "        self.models['GradientBoosting'].fit(self.X_train, self.y_train)\n",
    "        \n",
    "        self.models['KNN'] = KNNRegressor(n_neighbors=10)\n",
    "        self.models['KNN'].fit(self.X_train, self.y_train)\n",
    "        \n",
    "        print(\"Done.\")\n",
    "        return self\n",
    "    \n",
    "    def train_stacking_walkforward(self):\n",
    "        print(\"\\nTraining stacking model...\")\n",
    "        \n",
    "        base_names = ['Ridge', 'RF', 'GradientBoosting', 'KNN']\n",
    "        n_models = len(base_names)\n",
    "        \n",
    "        X_combined = np.vstack([self.X_train, self.X_val])\n",
    "        y_combined = np.concatenate([self.y_train, self.y_val])\n",
    "        \n",
    "        min_train_size = int(0.55 * len(X_combined))\n",
    "        step_size = int(0.05 * len(X_combined))\n",
    "        \n",
    "        wf_train_preds = []\n",
    "        wf_train_actuals = []\n",
    "        \n",
    "        current_end = min_train_size\n",
    "        n_windows = 0\n",
    "        \n",
    "        while current_end < len(X_combined):\n",
    "            val_start = current_end\n",
    "            val_end = min(current_end + step_size, len(X_combined))\n",
    "            \n",
    "            if val_end - val_start < 10:\n",
    "                break\n",
    "            \n",
    "            X_wf_train = X_combined[:current_end]\n",
    "            y_wf_train = y_combined[:current_end]\n",
    "            X_wf_val = X_combined[val_start:val_end]\n",
    "            y_wf_val = y_combined[val_start:val_end]\n",
    "            \n",
    "            window_preds = np.zeros((len(X_wf_val), n_models))\n",
    "            \n",
    "            for i, name in enumerate(base_names):\n",
    "                if name == 'Ridge':\n",
    "                    model = RidgeRegression(alpha=1.0)\n",
    "                elif name == 'RF':\n",
    "                    model = RandomForestRegressor(n_trees=200, max_depth=8, min_samples_split=5)\n",
    "                elif name == 'GradientBoosting':\n",
    "                    model = GradientBoosting(learning_rate=0.03, n_trees=300, max_depth=2)\n",
    "                else:\n",
    "                    model = KNNRegressor(n_neighbors=10)\n",
    "                \n",
    "                try:\n",
    "                    model.fit(X_wf_train, y_wf_train)\n",
    "                    window_preds[:, i] = model.predict(X_wf_val)\n",
    "                except:\n",
    "                    window_preds[:, i] = 0\n",
    "            \n",
    "            wf_train_preds.append(window_preds)\n",
    "            wf_train_actuals.append(y_wf_val)\n",
    "            \n",
    "            n_windows += 1\n",
    "            current_end += step_size\n",
    "        \n",
    "        wf_train_preds_all = np.vstack(wf_train_preds)\n",
    "        wf_train_actuals_all = np.concatenate(wf_train_actuals)\n",
    "        \n",
    "        if np.any(np.isnan(wf_train_preds_all)):\n",
    "            for col in range(wf_train_preds_all.shape[1]):\n",
    "                col_data = wf_train_preds_all[:, col]\n",
    "                if np.any(np.isnan(col_data)):\n",
    "                    col_mean = np.nanmean(col_data) if not np.all(np.isnan(col_data)) else 0\n",
    "                    wf_train_preds_all[np.isnan(col_data), col] = col_mean\n",
    "        \n",
    "        alpha_candidates = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]\n",
    "        n_meta_val = int(0.2 * len(wf_train_preds_all))\n",
    "        meta_train_X = wf_train_preds_all[:-n_meta_val]\n",
    "        meta_train_y = wf_train_actuals_all[:-n_meta_val]\n",
    "        meta_val_X = wf_train_preds_all[-n_meta_val:]\n",
    "        meta_val_y = wf_train_actuals_all[-n_meta_val:]\n",
    "        \n",
    "        best_alpha = 0.05\n",
    "        best_score = float('inf')\n",
    "        \n",
    "        for alpha in alpha_candidates:\n",
    "            meta_temp = RidgeRegression(alpha=alpha)\n",
    "            meta_temp.fit(meta_train_X, meta_train_y)\n",
    "            val_pred = meta_temp.predict(meta_val_X)\n",
    "            rmse = np.sqrt(np.mean((meta_val_y - val_pred) ** 2))\n",
    "            if rmse < best_score:\n",
    "                best_score = rmse\n",
    "                best_alpha = alpha\n",
    "        \n",
    "        self.meta_model = RidgeRegression(alpha=best_alpha)\n",
    "        self.meta_model.fit(wf_train_preds_all, wf_train_actuals_all)\n",
    "        \n",
    "        print(f\"\\nMeta-model weights (alpha={best_alpha}):\")\n",
    "        base_names = ['Ridge', 'RF', 'GradientBoosting', 'KNN']\n",
    "        for i, name in enumerate(base_names):\n",
    "            print(f\"  {name}: {self.meta_model.w[i+1]:.4f}\")\n",
    "        print(f\"  Intercept: {self.meta_model.w[0]:.4f}\")\n",
    "        \n",
    "        test_preds = np.zeros((len(self.X_test), n_models))\n",
    "        for i, name in enumerate(base_names):\n",
    "            preds = self.models[name].predict(self.X_test)\n",
    "            if np.any(np.isnan(preds)):\n",
    "                preds = np.zeros(len(self.X_test))\n",
    "            test_preds[:, i] = preds\n",
    "        \n",
    "        self.predictions['Stacking'] = self.meta_model.predict(test_preds)\n",
    "        print(\"Done.\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def evaluate_models(self):\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"RESULTS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        results = []\n",
    "        for name, model in self.models.items():\n",
    "            y_pred = model.predict(self.X_test)\n",
    "            self.predictions[name] = y_pred\n",
    "            \n",
    "            rmse = np.sqrt(np.mean((self.y_test - y_pred) ** 2))\n",
    "            mae = np.mean(np.abs(self.y_test - y_pred))\n",
    "            \n",
    "            results.append({\"Model\": name, \"RMSE\": rmse, \"MAE\": mae})\n",
    "        \n",
    "        stack_pred = self.predictions['Stacking']\n",
    "        stack_rmse = np.sqrt(np.mean((self.y_test - stack_pred) ** 2))\n",
    "        stack_mae = np.mean(np.abs(self.y_test - stack_pred))\n",
    "        results.append({\"Model\": \"Stacking\", \"RMSE\": stack_rmse, \"MAE\": stack_mae})\n",
    "        \n",
    "        print(\"\\nReturn Prediction:\")\n",
    "        print(pd.DataFrame(results).to_string(index=False))\n",
    "        \n",
    "        print(\"\\nPrice Prediction:\")\n",
    "        price_results = []\n",
    "        for name in ['Ridge', 'RF', 'GradientBoosting', 'KNN', 'Stacking']:\n",
    "            return_pred = self.predictions[name]\n",
    "            price_pred = self.price_test * (1 + return_pred)\n",
    "            price_actual = self.price_test * (1 + self.y_test)\n",
    "            \n",
    "            price_rmse = np.sqrt(np.mean((price_actual - price_pred) ** 2))\n",
    "            price_mae = np.mean(np.abs(price_actual - price_pred))\n",
    "            \n",
    "            price_results.append({\"Model\": name, \"RMSE\": price_rmse, \"MAE\": price_mae})\n",
    "        \n",
    "        print(pd.DataFrame(price_results).to_string(index=False))\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        return self\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PHẦN 3: CHẠY CHƯƠNG TRÌNH\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"NYA Stock Prediction - Stacking Ensemble\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    predictor = NYAStackingPredictor('indexProcessed.csv')\n",
    "    predictor.load_and_filter_data() \\\n",
    "             .create_features() \\\n",
    "             .prepare_data() \\\n",
    "             .train_base_models() \\\n",
    "             .train_stacking_walkforward() \\\n",
    "             .evaluate_models()\n",
    "    \n",
    "    # Lưu model\n",
    "    with open('nya_model.pkl', 'wb') as f:\n",
    "        pickle.dump(predictor, f)\n",
    "    \n",
    "    file_size = os.path.getsize('nya_model.pkl') / 1024 / 1024\n",
    "    print(f\"\\nModel saved: nya_model.pkl ({file_size:.2f} MB)\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Chào mừng bạn đến với Colab",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
